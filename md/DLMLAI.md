+++
title = "AI/ML/DL a pragmatic maverick's perspective"
description = "YMMV!"
tags = [
    "ML",
    "DL",
    "AI",
]
date = "2019-02-09"
categories = [
    "post",
]
highlight = "true"
+++
# The whole ML/AI/Deep Learning thing

After reading StJohn Deakin's excellent take on all things AI, I  wanted to get down where I stand on the whole thing!

## Deep Learning
- Only suits certain large data problems (vision/speech).
- Only suits problems where manipulation of non-platonic concepts prevail
(no symbolic reality... although some work has been done on this).
- Largely empirical (other than when Bayes is applied). This gung-ho
is refreshing.
- Researchers it attracts are low grade scientists (like me),
compared to, say, biologists.
- Hardware is the limiting liberating factor.
- Upside (big) is it's solving vision/speech problems in the here and now,
 we didn't/don't have any better ideas!
- The above plays wonderfully into the hands of large digital corporations and governments, who have the motivation, data and hardware.
 
## ML
- ML is a well established branch of statistics with known principles
and bounds.
- Practically, it can be applied to small data-sets and has application in
many domains, now we routinely collect digital data. In the same way the
web freed text, ML will free data - I mean that both positively and negatively.
- I'm not sure anything super new is coming here in improving
classifiers (the workhorse ML approach), it's all been incremental for
a while.
- Everybody in this field should have read [David Mackay's book](http://www.inference.org.uk/itila/book.html) -
that's not up for argument.

## AI
- I can't even begin to think how misused this term is, would it be better
if we called this planning/optimisation algorithms?
- I'm pretty certain we can't do artificially "average" tasks yet
(like driving a car ;))- it seems daft
to think we can leapfrog all that foundation and hit the moving target that
is "intelligence".
- Bayes is subjective logic, that problem is quite solved. As David
Mackay says  it even explains Occams razor.
- I'm not sure we can introspect enough to build AI - I think our human capacity
for understanding ourselves only goes so far, perhaps in the same way
that we find
ourselves with quantum, the closest we'll get is a mathematical
formalism which will
seem unwholesome and unrealistic. I guess the answer is the same:
"shut up and calculate!"
- I favour a measure of intelligence that is grounded in the real and practical,
maybe aligned with a biological hierarchy, or key achievable
evolutionary advantages
(I'm thinking trapping and farming!). At least then we can measure progress.
